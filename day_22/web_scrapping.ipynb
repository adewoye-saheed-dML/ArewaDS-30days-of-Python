{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b059aaf8-7be7-4333-ba08-fca85dd3cc31",
   "metadata": {},
   "source": [
    "# Day_22 : Python web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab144e27-e851-4956-beb5-b7c3df0dd9b6",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7149502-ec82-4569-8fa9-f11b209e6725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and stored as \"scraped_data.json\"\n"
     ]
    }
   ],
   "source": [
    "# Scraping a website and storing the data as json file\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = 'http://www.bu.edu/president/boston-university-facts-stats/'\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# extracting all text from paragraphs:\n",
    "data = {'paragraphs': [p.get_text() for p in soup.find_all('p')]}\n",
    "\n",
    "# Store the data as JSON\n",
    "with open('scraped_data.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print('Data scraped and stored as \"scraped_data.json\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe45cb7-eecf-4c6c-83fb-d49f08f05a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table data has been extracted and saved to 'table_data.json'.\n"
     ]
    }
   ],
   "source": [
    "# Extracting the table in a url\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# URL of the webpage containing the table\n",
    "url = \"https://archive.ics.uci.edu/dataset/602/dry+bean+dataset.php\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table you want to extract (you may need to inspect the HTML to find the appropriate tags)\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Initialize an empty list to store the table data\n",
    "    table_data = []\n",
    "\n",
    "    # Extract rows and columns from the table\n",
    "    for row in table.find_all('tr'):\n",
    "        row_data = [cell.text.strip() for cell in row.find_all(['th', 'td'])]\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    # Convert the table data to a JSON format\n",
    "    json_data = json.dumps(table_data, indent=2)\n",
    "\n",
    "    # Save the JSON data to a file\n",
    "    with open('table_data.json', 'w') as json_file:\n",
    "        json_file.write(json_data)\n",
    "\n",
    "    print(\"Table data has been extracted and saved to 'table_data.json'.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Check the URL or try again later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1b325a-3221-4f9a-ad52-39e95f9032a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidents data scraped and stored as \"presidents_data.json\"\n"
     ]
    }
   ],
   "source": [
    "# Scraping the presidents table and storing the data \n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the table containing the list of presidents\n",
    "presidents_table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Initialize empty list to store presidents' data\n",
    "presidents_data = []\n",
    "\n",
    "# Iterate over rows in the table\n",
    "for row in presidents_table.find_all('tr')[1:]:  # Skip the header row\n",
    "    columns = row.find_all(['th', 'td'])\n",
    "\n",
    "    # Extract data from each column\n",
    "    number = columns[0].get_text(strip=True)\n",
    "    president = columns[1].get_text(strip=True)\n",
    "    presidency = columns[2].get_text(strip=True)\n",
    "    term = columns[3].get_text(strip=True)\n",
    "    party = columns[4].get_text(strip=True)\n",
    "\n",
    "    # Create a dictionary for each president's data\n",
    "    president_info = {\n",
    "        'Number': number,\n",
    "        'President': president,\n",
    "        'Presidency': presidency,\n",
    "        'Term': term,\n",
    "        'Party': party\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    presidents_data.append(president_info)\n",
    "\n",
    "# Store the data as JSON\n",
    "with open('presidents_data.json', 'w') as json_file:\n",
    "    json.dump(presidents_data, json_file, indent=2)\n",
    "\n",
    "print('Presidents data scraped and stored as \"presidents_data.json\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b7264-8816-47f1-abfe-192d8f1fdc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
